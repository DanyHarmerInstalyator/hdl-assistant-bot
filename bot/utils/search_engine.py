import os
import json
import logging
import re
from typing import List, Dict, Any, Tuple
from difflib import SequenceMatcher

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤–∞—à–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
from .yandex_disk_client import (
    normalize_with_synonyms, 
    smart_document_search as yandex_smart_search,
    build_docs_url
)

class SearchEngine:
    def __init__(self, index_file: str = "data/cache/file_index.json"):
        self.index_file = index_file
        self.file_index = self.load_index()
        self.synonyms = {
            "–∫–∞–±–µ–ª—å": ["cable", "–ø—Ä–æ–≤–æ–¥", "wire", "–∫–∞–±–µ–ª"],
            "knx": ["–∫–Ω–∏–∫—Å", "–∫–Ω—Ö", "knx"],
            "–¥–∞—Ç—á–∏–∫": ["sensor", "—Å–µ–Ω—Å–æ—Ä", "–¥–µ—Ç–µ–∫—Ç–æ—Ä"],
            "—Ä–µ–ª–µ": ["relay", "—Ä–µ–ª", "–ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å"],
            "–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä": ["controller", "control", "—É–ø—Ä–∞–≤–ª—è—é—â–∏–π"],
            "–ø–∞–Ω–µ–ª—å": ["panel", "–ø–∞–Ω–µ–ª"],
            "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è": ["manual", "instruction", "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ"],
            "–ø–∞—Å–ø–æ—Ä—Ç": ["datasheet", "technical", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π"],
            "urri": ["—É—Ä—Ä–∏", "—é—Ä–∏–∏"],
            "hdl": ["—Ö–¥–ª"],
            "buspro": ["–±–∞—Å–ø—Ä–æ", "–±–∞—Å–ø—Ä"],
            "matech": ["–º–∞—Ç–µ–∫", "–º–∞—Ç–µ—á"],
            "yeelight": ["–π–∏–ª–∞–π—Ç", "yee light"],
            "easycool": ["–∏–∑–∏–∫—É–ª", "easy cool", "–∏–∑–∏ –∫—É–ª"],
            "–∫–∞–±–µ–ª": ["–∫–∞–±–µ–ª—å", "cable"],
            "–∑–∞–º–æ–∫": ["lock", "–¥–≤–µ—Ä–Ω–æ–π –∑–∞–º–æ–∫", "door lock"],
            "–∑–∞–º–∫–∏": ["locks", "–¥–≤–µ—Ä–Ω—ã–µ –∑–∞–º–∫–∏", "door locks"],
            "–¥–≤–µ—Ä–Ω–æ–π": ["door", "–¥–≤–µ—Ä–Ω–æ–π"],
            "iot": ["–∏–æ—Ç", "iot systems", "–∞–π–æ—Ç–∏"],
            "—Ç–µ—Ö–Ω–∏—á–∫–∞": ["—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è", "technical", "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "–ø–∞—Å–ø–æ—Ä—Ç"]
        }

        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø–∞–ø–∫–∏ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞
        self.folder_links = {
            "–∫–∞–±–µ–ª—å": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "–∫–∞–±–µ–ª–∏": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "cable": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∫–∞–±–µ–ª—å": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "–∫–∞–±–µ–ª—å –∏–æ—Ç": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "–∫–∞–±–µ–ª—å iot": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "iot –∫–∞–±–µ–ª—å": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            
            "–∑–∞–º–æ–∫": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–∑–∞–º–∫–∏": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–¥–≤–µ—Ä–Ω–æ–π –∑–∞–º–æ–∫": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–¥–≤–µ—Ä–Ω—ã–µ –∑–∞–º–∫–∏": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–∑–∞–º–∫–∏ iot": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–∑–∞–º–∫–∏ –∏–æ—Ç": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "iot –∑–∞–º–æ–∫": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "door lock": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems"
        }

    def load_index(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if os.path.exists(self.index_file):
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
                    if isinstance(data, dict):
                        return list(data.values())
                    return data
            else:
                logging.warning(f"Index file {self.index_file} not found")
                return []
        except Exception as e:
            logging.error(f"Error loading index: {e}")
            return []

    def normalize_text(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞"""
        if not text:
            return ""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        return normalize_with_synonyms(text)

    def expand_synonyms(self, query: str) -> List[str]:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏"""
        normalized_query = self.normalize_text(query)
        words = normalized_query.split()
        expanded_queries = [normalized_query]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
        for i, word in enumerate(words):
            if word in self.synonyms:
                for synonym in self.synonyms[word]:
                    new_words = words.copy()
                    new_words[i] = synonym
                    expanded_queries.append(' '.join(new_words))
        
        return list(set(expanded_queries))

    def should_redirect_to_folder(self, query: str) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ –ø–∞–ø–∫—É –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞"""
        query_lower = query.lower().strip()
        
        # –ò–°–ö–õ–Æ–ß–ê–ï–ú –∑–∞–ø—Ä–æ—Å—ã —Å KNX - –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –∏–¥—Ç–∏ –∫ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–º—É –ø—Ä–∞–≤–∏–ª—É
        if "knx" in query_lower:
            return False, ""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if query_lower in self.folder_links:
            return True, self.folder_links[query_lower]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –∫–∞–±–µ–ª–µ–π (–±–µ–∑ KNX)
        cable_keywords = ["–∫–∞–±–µ–ª—å", "cable", "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∫–∞–±–µ–ª—å", "–∫–∞–±–µ–ª—å –∏–æ—Ç", "–∫–∞–±–µ–ª—å iot", "iot –∫–∞–±–µ–ª—å"]
        if any(keyword in query_lower for keyword in cable_keywords) and "knx" not in query_lower:
            return True, self.folder_links["–∫–∞–±–µ–ª—å"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –∑–∞–º–∫–æ–≤
        lock_keywords = ["–∑–∞–º–æ–∫", "–∑–∞–º–∫–∏", "–¥–≤–µ—Ä–Ω–æ–π –∑–∞–º–æ–∫", "–¥–≤–µ—Ä–Ω—ã–µ –∑–∞–º–∫–∏", "–∑–∞–º–∫–∏ iot", "–∑–∞–º–∫–∏ –∏–æ—Ç", "iot –∑–∞–º–æ–∫"]
        if any(keyword in query_lower for keyword in lock_keywords):
            return True, self.folder_links["–∑–∞–º–∫–∏"]
        
        return False, ""

    def is_knx_cable_query(self, query: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –ø–æ–∏—Å–∫–æ–º –∫–∞–±–µ–ª—è KNX"""
        query_lower = query.lower().strip()
        
        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–±–µ–ª—è KNX
        exact_knx_queries = [
            "–∫–∞–±–µ–ª—å knx", "knx –∫–∞–±–µ–ª—å", "cable knx", "knx cable",
            "knx –∫–∞–±–µ–ª", "ye00820", "j-y(st)y", "2x2x0,8"
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if any(exact_query in query_lower for exact_query in exact_knx_queries):
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        words = query_lower.split()
        has_knx = "knx" in words or any("knx" in word for word in words)
        has_cable = any(word in ["–∫–∞–±–µ–ª—å", "cable", "–∫–∞–±–µ–ª"] for word in words)
        
        return has_knx and has_cable

    def find_knx_cable_files(self) -> List[Dict[str, Any]]:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—â–µ—Ç —Ñ–∞–π–ª—ã –∫–∞–±–µ–ª—è KNX"""
        knx_cable_files = []
        
        for file_data in self.file_index:
            file_name = file_data.get("name", "").lower()
            file_path = file_data.get("path", "").lower()
            search_text = f"{file_name} {file_path}"
            
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –∫–∞–±–µ–ª—è KNX –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
            if any(keyword in search_text for keyword in [
                "ye00820", 
                "j-y(st)y", 
                "2x2x0,8",
                "knx –∫–∞–±–µ–ª—å",
                "–∫–∞–±–µ–ª—å knx",
                "–∫–∞–±–µ–ª—å j-y",
                "j-y st y"
            ]):
                knx_cable_files.append(file_data)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        scored_files = []
        for file_data in knx_cable_files:
            score = 0
            file_name = file_data.get("name", "").lower()
            file_path = file_data.get("path", "").lower()
            search_text = f"{file_name} {file_path}"
            
            # –í—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è YE00820
            if "ye00820" in search_text:
                score += 1000
            if "j-y(st)y" in search_text:
                score += 500
            if "2x2x0,8" in search_text:
                score += 300
            if "knx –∫–∞–±–µ–ª—å" in search_text or "–∫–∞–±–µ–ª—å knx" in search_text:
                score += 200
                
            scored_files.append((score, file_data))
        
        scored_files.sort(key=lambda x: x[0], reverse=True)
        return [file_data for score, file_data in scored_files]

    def calculate_relevance(self, file_data: Dict[str, Any], query_variants: List[str]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞ –∑–∞–ø—Ä–æ—Å—É"""
        max_score = 0
        
        file_name = file_data.get("name", "").lower()
        file_path = file_data.get("path", "").lower()
        norm_name = file_data.get("norm_name", "").lower()
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è –ø–æ–∏—Å–∫–∞
        search_text = f"{file_name} {file_path} {norm_name}"
        
        for query in query_variants:
            score = 0
            
            # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (—Å–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            if query in file_name:
                score += 10
                
            # 2. –í—Å–µ —Å–ª–æ–≤–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
            query_words = set(query.split())
            file_name_words = set(file_name.split())
            if query_words.issubset(file_name_words):
                score += 8
                
            # 3. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –∏–º–µ–Ω–∏
            if query in norm_name:
                score += 7
                
            # 4. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –ø—É—Ç–∏
            if query in file_path:
                score += 6
                
            # 5. –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å—Ç—Ä–æ–∫)
            name_similarity = SequenceMatcher(None, query, file_name).ratio()
            path_similarity = SequenceMatcher(None, query, file_path).ratio()
            score += max(name_similarity, path_similarity) * 5
            
            # 6. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
            for word in query.split():
                if word in file_name:
                    score += 2
                if word in norm_name:
                    score += 3
                if word in file_path:
                    score += 1
            
            # 7. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∫–∞–±–µ–ª–µ–π KNX
            if "–∫–∞–±–µ–ª—å" in query and "knx" in query:
                if "ye00820" in search_text:
                    score += 100
                if "j-y(st)y" in search_text:
                    score += 80
                if "2x2x0,8" in search_text:
                    score += 60
                if "knx –∫–∞–±–µ–ª—å" in search_text or "–∫–∞–±–µ–ª—å knx" in search_text:
                    score += 40
                if "–¥–∞—Ç—á–∏–∫" in search_text:
                    score -= 50
            
            max_score = max(max_score, score)
        
        return max_score

    def search(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        if not query or not self.file_index:
            return []
        
        logging.info(f"üîç –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫: '{query}'")
        
        # –†–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
        query_variants = self.expand_synonyms(query)
        logging.info(f"üìã –í–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø—Ä–æ—Å–∞: {query_variants}")
        
        scored_results = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        for file_data in self.file_index:
            relevance = self.calculate_relevance(file_data, query_variants)
            
            if relevance > 0:
                scored_results.append({
                    **file_data,
                    "relevance": relevance
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        scored_results.sort(key=lambda x: x["relevance"], reverse=True)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        for i, result in enumerate(scored_results[:5]):
            logging.info(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç {i+1}: {result['name']} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['relevance']:.2f})")
        
        return scored_results[:limit]

    def hybrid_search(self, query: str, limit: int = 3) -> List[Dict[str, Any]]:
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞,
        –∑–∞—Ç–µ–º –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
        """
        # 1. –°–ü–ï–¶–ò–ê–õ–¨–ù–û–ï –ü–†–ê–í–ò–õ–û –î–õ–Ø –ö–ê–ë–ï–õ–Ø KNX - –°–ê–ú–´–ô –í–´–°–®–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢
        if self.is_knx_cable_query(query):
            knx_cable_results = self.find_knx_cable_files()
            if knx_cable_results:
                logging.info(f"üéØ –ö–ê–ë–ï–õ–¨ KNX: –Ω–∞–π–¥–µ–Ω–æ {len(knx_cable_results)} —Ñ–∞–π–ª–æ–≤")
                return knx_cable_results[:limit]

        # 2. –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø –ù–ê –ü–ê–ü–ö–ò –Ø–ù–î–ï–ö–°.–î–ò–°–ö–ê
        should_redirect, folder_link = self.should_redirect_to_folder(query)
        if should_redirect:
            logging.info(f"üéØ –ü–ï–†–ï–ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï: –∑–∞–ø—Ä–æ—Å '{query}' ‚Üí –ø–∞–ø–∫–∞ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Å—Å—ã–ª–∫–æ–π –Ω–∞ –ø–∞–ø–∫—É
            return [{
                "name": f"üìÅ –ü–∞–ø–∫–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π: {query}",
                "path": folder_link,
                "is_folder_link": True,
                "folder_link": folder_link
            }]

        # 3. –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–û–ò–°–ö
        improved_results = self.search(query, limit)
        if improved_results:
            logging.info(f"‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞—à–µ–ª {len(improved_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return improved_results
        
        # 4. –°–¢–ê–†–´–ô –ü–û–ò–°–ö –î–õ–Ø –û–ë–†–ê–¢–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
        logging.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º")
        try:
            old_results = yandex_smart_search(query)
            return old_results[:limit]
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç–∞—Ä–æ–º –ø–æ–∏—Å–∫–µ: {e}")
            return []


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async def smart_document_search(query: str, limit: int = 3) -> List[Dict[str, Any]]:
    """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
    search_engine = SearchEngine()
    return search_engine.hybrid_search(query, limit)

def search_in_file_index(query: str, index_path: str = "data/cache/file_index.json") -> List[Dict]:
    """–°—Ç–∞—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
    search_engine = SearchEngine(index_path)
    return search_engine.search(query)

def has_only_technical_files(results: List[Dict[str, Any]]) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
    """
    # –ï—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–∞–ø–∫—É - –Ω–µ —Å—á–∏—Ç–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º
    if results and results[0].get("is_folder_link"):
        return False
        
    technical_patterns = ["r5-", "–¥–∞—Ç—á–∏–∫", "sensor", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫", "–ø–∞—Å–ø–æ—Ä—Ç", "technical"]
    
    for file_data in results:
        file_name = file_data.get("name", "").lower()
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –æ–¥–∏–Ω –ù–ï —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ñ–∞–π–ª - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False
        if not any(pattern in file_name for pattern in technical_patterns):
            return False
    
    # –í—Å–µ —Ñ–∞–π–ª—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ
    return True

def should_use_ai_directly(query: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —Å—Ä–∞–∑—É –ø–æ–¥–∫–ª—é—á–∞—Ç—å –ò–ò –±–µ–∑ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    """
    query_lower = query.lower()
    
    # –ë–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ê–ª–∏—Å—ã
    alisa_keywords = [
        "–∞–ª–∏—Å", "–≥–æ–ª–æ—Å–æ–≤", "—è–Ω–¥–µ–∫—Å –∞–ª–∏—Å", "yandex alice", "alisa", 
        "–∞–ª–∏—Å—É", "–∞–ª–∏—Å–æ–π", "–∞–ª–∏—Å—ã", "–≥–æ–ª–æ—Å–æ–≤–æ–π", "–≥–æ–ª–æ—Å–æ–≤–æ–µ"
    ]
    
    # –ë–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
    integration_keywords = [
        "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏", "–ø–æ–¥–∫–ª—é—á–∏", "–Ω–∞—Å—Ç—Ä–æ–∏", "—Å–≤—è–∑–∞—Ç—å", "–æ–±—ä–µ–¥–∏–Ω–∏—Ç—å", 
        "—á–µ—Ä–µ–∑", "—Å –ø–æ–º–æ—â—å—é", "–≤–º–µ—Å—Ç–µ", "—Å–æ–≤–º–µ—Å—Ç–Ω", "–∫–∞–∫ —Å–¥–µ–ª–∞–≤", 
        "–∫–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏–≤", "–∫–∞–∫ –ø–æ–¥–∫–ª—é—á–∏–≤"
    ]
    
    has_alisa = any(keyword in query_lower for keyword in alisa_keywords)
    has_integration = any(keyword in query_lower for keyword in integration_keywords)
    has_knx = "knx" in query_lower or "–∫–Ω–∏–∫—Å" in query_lower or "–∫–Ω—Ö" in query_lower
    
    # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ï—Å–ª–∏ –µ—Å—Ç—å –ê–ª–∏—Å–∞ –ò (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ò–õ–ò KNX) - —Å—Ä–∞–∑—É –∫ –ò–ò
    if has_alisa and (has_integration or has_knx):
        print("‚úÖ –†–µ—à–µ–Ω–∏–µ: –ê–ª–∏—Å–∞ + –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è/KNX ‚Üí —Å—Ä–∞–∑—É –∫ –ò–ò")
        return True
    
    # –°–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–æ –ê–ª–∏—Å—É
    question_words = ["–∫–∞–∫", "—á—Ç–æ", "–∫–∞–∫–æ–π", "–∫–∞–∫–∞—è", "–º–æ–∂–Ω–æ –ª–∏", "–≤–æ–∑–º–æ–∂–Ω–æ –ª–∏", "–∫–∞–∫–æ–≤", "–ø–æ–¥—Å–∫–∞–∂–∏", "–ø–æ—Å–æ–≤–µ—Ç—É–π"]
    if any(word in query_lower for word in question_words) and has_alisa:
        print("‚úÖ –†–µ—à–µ–Ω–∏–µ: –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –ê–ª–∏—Å—É ‚Üí –∫ –ò–ò")
        return True
    
    # –õ—é–±–æ–π –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∞—â–∏–π "–ê–ª–∏—Å–∞" –∏ "KNX" –≤–º–µ—Å—Ç–µ
    if has_alisa and has_knx:
        print("‚úÖ –†–µ—à–µ–Ω–∏–µ: –ê–ª–∏—Å–∞ + KNX ‚Üí —Å—Ä–∞–∑—É –∫ –ò–ò")
        return True
    
    print("‚ùå –†–µ—à–µ–Ω–∏–µ: –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
    return False