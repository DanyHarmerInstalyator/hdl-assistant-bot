import os
import json
import logging
import re
import requests
import urllib.parse
from typing import List, Dict, Any, Tuple
from difflib import SequenceMatcher
from dotenv import load_dotenv

load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞
YANDEX_DISK_TOKEN = os.getenv("YANDEX_DISK_TOKEN")
YANDEX_DISK_FOLDER_PATH = os.getenv("YANDEX_DISK_FOLDER_PATH", "/")
DOCS_PUBLIC_KEY = os.getenv("DOCS_PUBLIC_KEY")

if not YANDEX_DISK_TOKEN:
    raise ValueError("‚ùå YANDEX_DISK_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
if not DOCS_PUBLIC_KEY:
    raise ValueError("‚ùå DOCS_PUBLIC_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")

BASE_URL = "https://cloud-api.yandex.net/v1/disk"
HEADERS = {
    "Authorization": f"OAuth {YANDEX_DISK_TOKEN}"
}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
SYNONYMS = {
    "–∫–∞–±–µ–ª—å": "cable", "–∫–Ω–∏–∫—Å": "knx", "–∫–Ω—Ö": "knx", "–¥–∞—Ç—á–∏–∫": "sensor",
    "—Ä–µ–ª–µ": "relay", "–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä": "controller", "–ø–∞–Ω–µ–ª—å": "panel",
    "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è": "manual", "–ø–∞—Å–ø–æ—Ä—Ç": "datasheet", "—É—Ä—Ä–∏": "urri",
    "—é—Ä–∏–∏": "urri", "—Ö–¥–ª": "hdl", "–±–∞—Å–ø—Ä–æ": "buspro", "–±–∞—Å–ø—Ä": "buspro",
    "–º–∞—Ç–µ–∫": "matech", "–º–∞—Ç–µ—á": "matech", "–π–∏–ª–∞–π—Ç": "yeelight",
    "–∏–∑–∏–∫—É–ª": "easycool", "–∫–∞–±–µ–ª": "cable", "–∑–∞–º–æ–∫": "lock",
    "–¥–≤–µ—Ä–Ω–æ–π": "door", "–∏–æ—Ç": "iot", "–∞–π–æ—Ç–∏": "iot", "—Ç–µ—Ö–Ω–∏—á–∫–∞": "technical"
}

def normalize_with_synonyms(query: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏"""
    query_lower = query.lower().strip()
    for wrong, correct in sorted(SYNONYMS.items(), key=lambda x: -len(x[0])):
        query_lower = query_lower.replace(wrong, correct)
    cleaned = re.sub(r"[^a-z0-9\s]", " ", query_lower)
    return re.sub(r"\s+", " ", cleaned).strip()

def get_folder_contents(path: str) -> List[Dict]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–∞–ø–∫–∏ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞"""
    url = f"{BASE_URL}/resources"
    params = {"path": path, "limit": 1000}
    response = requests.get(url, headers=HEADERS, params=params)
    response.raise_for_status()
    data = response.json()
    return data.get("_embedded", {}).get("items", [])

def build_docs_url(file_path: str) -> str:
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ URL –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    base = YANDEX_DISK_FOLDER_PATH.rstrip("/")
    if file_path.startswith(base):
        relative_path = file_path[len(base):].lstrip("/")
    else:
        relative_path = file_path.lstrip("/")

    encoded_docs_key = urllib.parse.quote(DOCS_PUBLIC_KEY, safe="")
    encoded_path = urllib.parse.quote(relative_path, safe="/")
    filename = os.path.basename(file_path)
    encoded_name = urllib.parse.quote(filename, safe="")

    return (
        f"https://docs.360.yandex.ru/docs/view?"
        f"url=ya-disk-public%3A%2F%2F{encoded_docs_key}%3A%2F{encoded_path}"
        f"&name={encoded_name}&nosw=1"
    )

class SearchEngine:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""

    def __init__(self, index_file: str = "data/cache/file_index.json"):
        self.index_file = index_file
        self.file_index = self.load_index()
        self._normalize_cache = {}

        self.synonyms = {
            "–∫–∞–±–µ–ª—å": ["cable", "–ø—Ä–æ–≤–æ–¥", "wire", "–∫–∞–±–µ–ª"],
            "knx": ["–∫–Ω–∏–∫—Å", "–∫–Ω—Ö", "knx"],
            "–¥–∞—Ç—á–∏–∫": ["sensor", "—Å–µ–Ω—Å–æ—Ä", "–¥–µ—Ç–µ–∫—Ç–æ—Ä"],
            "—Ä–µ–ª–µ": ["relay", "—Ä–µ–ª", "–ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å"],
            "–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä": ["controller", "control", "—É–ø—Ä–∞–≤–ª—è—é—â–∏–π"],
            "–ø–∞–Ω–µ–ª—å": ["panel", "–ø–∞–Ω–µ–ª"],
            "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è": ["manual", "instruction", "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ"],
            "–ø–∞—Å–ø–æ—Ä—Ç": ["datasheet", "technical", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π"],
            "–∫–∞—Ä–Ω–∏–∑": ["curtain", "track", "—à—Ç–æ—Ä–∞", "—Ä–µ–ª—å—Å"],
            "—Ä–∞–¥–∏—É—Å–Ω—ã–π": ["–∏–∑–æ–≥–Ω—É—Ç—ã–π", "–¥—É–≥–æ–≤–æ–π", "curved"],
            "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è": ["spec", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏", "—Ç–µ—Ö–Ω–∏—á–∫–∞"],
            "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä": ["ac", "air conditioner", "–∫–ª–∏–º–∞—Ç", "—Å–ø–ª–∏—Ç"],
            "—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å": ["—Å–æ–≤–º–µ—Å—Ç–∏–º", "—Ä–∞–±–æ—Ç–∞–µ—Ç —Å", "–ø–æ–¥–¥–µ—Ä–∂–∫–∞", "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è"],
            "–º–æ–¥–µ–ª—å": ["–º–æ–¥–µ–ª–∏", "–∞—Ä—Ç–∏–∫—É–ª", "—Å–µ—Ä–∏—è"],
            "urri": ["—É—Ä—Ä–∏", "—é—Ä–∏–∏"],
            "hdl": ["—Ö–¥–ª"],
            "buspro": ["–±–∞—Å–ø—Ä–æ", "–±–∞—Å–ø—Ä"],
            "matech": ["–º–∞—Ç–µ–∫", "–º–∞—Ç–µ—á"],
            "yeelight": ["–π–∏–ª–∞–π—Ç", "yee light"],
            "easycool": ["–∏–∑–∏–∫—É–ª", "easy cool", "–∏–∑–∏ –∫—É–ª"],
            "–∫–∞–±–µ–ª": ["–∫–∞–±–µ–ª—å", "cable"],
            "–∑–∞–º–æ–∫": ["lock", "–¥–≤–µ—Ä–Ω–æ–π –∑–∞–º–æ–∫", "door lock"],
            "–∑–∞–º–∫–∏": ["locks", "–¥–≤–µ—Ä–Ω—ã–µ –∑–∞–º–∫–∏", "door locks"],
            "–¥–≤–µ—Ä–Ω–æ–π": ["door", "–¥–≤–µ—Ä–Ω–æ–π"],
            "iot": ["–∏–æ—Ç", "iot systems", "–∞–π–æ—Ç–∏"],
            "—Ç–µ—Ö–Ω–∏—á–∫–∞": ["—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è", "technical", "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "–ø–∞—Å–ø–æ—Ä—Ç"]
        }

        self.folder_links = {
            # –ö–∞–±–µ–ª–∏
            "–∫–∞–±–µ–ª—å": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "–∫–∞–±–µ–ª–∏": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "cable": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∫–∞–±–µ–ª—å": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "–∫–∞–±–µ–ª—å –∏–æ—Ç": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "–∫–∞–±–µ–ª—å iot": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",
            "iot –∫–∞–±–µ–ª—å": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/02.%20iOT%20%D0%9A%D0%B0%D0%B1%D0%B5%D0%BB%D1%8C",

            # –ó–∞–º–∫–∏
            "–∑–∞–º–æ–∫": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–∑–∞–º–∫–∏": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–¥–≤–µ—Ä–Ω–æ–π –∑–∞–º–æ–∫": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–¥–≤–µ—Ä–Ω—ã–µ –∑–∞–º–∫–∏": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–∑–∞–º–∫–∏ iot": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "–∑–∞–º–∫–∏ –∏–æ—Ç": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "iot –∑–∞–º–æ–∫": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",
            "door lock": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/04.%20%D0%94%D0%B2%D0%B5%D1%80%D0%BD%D1%8B%D0%B5%20%D0%B7%D0%B0%D0%BC%D0%BA%D0%B8%20iOT%20Systems",

            # –ê–ª–∏—Å–∞
            "–∞–ª–∏—Å–∞": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/02.%20HDL/09.%20%D0%98%D0%BD%D1%82%D0%B5%D0%B3%D1%80%D0%B0%D1%86%D0%B8%D1%8F%20%D1%81%20%D0%B3%D0%BE%D0%BB%D0%BE%D1%81%D0%BE%D0%B2%D1%8B%D0%BC%D0%B8%20%D0%B0%D1%81%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%B0%D0%BC%D0%B8.%20Buspro%20%D0%B8%20KNX",
            "—è–Ω–¥–µ–∫—Å –∞–ª–∏—Å–∞": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/02.%20HDL/09.%20%D0%98%D0%BD%D1%82%D0%B5%D0%B3%D1%80%D0%B0%D1%86%D0%B8%D1%8F%20%D1%81%20%D0%B3%D0%BE%D0%BB%D0%BE%D1%81%D0%BE%D0%B2%D1%8B%D0%BC%D0%B8%20%D0%B0%D1%81%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%B0%D0%BC%D0%B8.%20Buspro%20%D0%B8%20KNX",
            "–≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/02.%20HDL/09.%20%D0%98%D0%BD%D1%82%D0%B5%D0%B3%D1%80%D0%B0%D1%86%D0%B8%D1%8F%20%D1%81%20%D0%B3%D0%BE%D0%BB%D0%BE%D1%81%D0%BE%D0%B2%D1%8B%D0%BC%D0%B8%20%D0%B0%D1%81%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%B0%D0%BC%D0%B8.%20Buspro%20%D0%B8%20KNX",
            "mgwip": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/02.%20HDL/09.%20%D0%98%D0%BD%D1%82%D0%B5%D0%B3%D1%80%D0%B0%D1%86%D0%B8%D1%8F%20%D1%81%20%D0%B3%D0%BE%D0%BB%D0%BE%D1%81%D0%BE%D0%B2%D1%8B%D0%BC%D0%B8%20%D0%B0%D1%81%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%B0%D0%BC%D0%B8.%20Buspro%20%D0%B8%20KNX",

            # –ö–∞—Ä–Ω–∏–∑—ã ‚Äî —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            "–∫–∞—Ä–Ω–∏–∑ buspro": "https://disk.360.yandex.ru/d/20Q51Ey5rDMXqA",
            "–∫–∞—Ä–Ω–∏–∑ –±–∞—Å–ø—Ä–æ": "https://disk.360.yandex.ru/d/20Q51Ey5rDMXqA",
            "–∫–∞—Ä–Ω–∏–∑ –±–∞—Å –ø—Ä–æ": "https://disk.360.yandex.ru/d/20Q51Ey5rDMXqA",
            "–∫–∞—Ä–Ω–∏–∑—ã buspro": "https://disk.360.yandex.ru/d/20Q51Ey5rDMXqA",
            "–∫–∞—Ä–Ω–∏–∑—ã –±–∞—Å–ø—Ä–æ": "https://disk.360.yandex.ru/d/20Q51Ey5rDMXqA",
            "–∫–∞—Ä–Ω–∏–∑ knx": "https://disk.360.yandex.ru/d/x1w6XEUthCgTVg",
            "–∫–∞—Ä–Ω–∏–∑ –∫–Ω–∏–∫—Å": "https://disk.360.yandex.ru/d/x1w6XEUthCgTVg",
            "–∫–∞—Ä–Ω–∏–∑—ã knx": "https://disk.360.yandex.ru/d/x1w6XEUthCgTVg",
            "–∫–∞—Ä–Ω–∏–∑—ã –∫–Ω–∏–∫—Å": "https://disk.360.yandex.ru/d/x1w6XEUthCgTVg",
            "–∫–∞—Ä–Ω–∏–∑ –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª—É knx": "https://disk.360.yandex.ru/d/x1w6XEUthCgTVg",

            # –ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã ‚Äî —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã easycool": "https://disk.360.yandex.ru/d/EuWsEkI__LPmIQ",
            "easycool –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã": "https://disk.360.yandex.ru/d/EuWsEkI__LPmIQ",
            "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã coolautomation": "https://disk.360.yandex.ru/d/UVzihaR7eRIRmw",
            "coolautomation –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã": "https://disk.360.yandex.ru/d/UVzihaR7eRIRmw",

            # EasyCool
            "–∏–∑–∏–∫—É–ª": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "easycool": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "–∏–∑–∏ –∫—É–ª": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∏–∑–∏–∫—É–ª": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–∏–∫—É–ª": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "–ø–∞—Å–ø–æ—Ä—Ç –Ω–∞ –∏–∑–∏–∫—É–ª": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "–Ω—É–∂–Ω–∞ —Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∏–∑–∏–∫—É–ª": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "–∏–∑–∏–∫—É–ª –±–∞—Å–ø—Ä–æ": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "–∏–∑–∏–∫—É–ª knx": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
            "–∏–∑–∏–∫—É–ª buspro": "https://disk.360.yandex.ru/d/xJi6eEXBTq01sw/01.%20iOT%20Systems/03.%20iOT%20EasyCool",
        }

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        self._alisa_keywords = {"–∞–ª–∏—Å", "—è–Ω–¥–µ–∫—Å –∞–ª–∏—Å", "yandex alice", "alisa", "mgwip", "–≥–æ–ª–æ—Å–æ–≤", "–≥–æ–ª–æ—Å–æ–≤–æ–π", "–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç"}
        self._integration_keywords = {"–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏", "–Ω–∞—Å—Ç—Ä–æ–∏", "–ø–æ–¥–∫–ª—é—á–∏", "—Å–≤—è–∑–∫", "—Å–≤—è–∑–∞—Ç—å", "–æ–±—ä–µ–¥–∏–Ω–∏—Ç—å"}
        self._cable_keywords = {"–∫–∞–±–µ–ª—å", "cable", "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∫–∞–±–µ–ª—å", "–∫–∞–±–µ–ª—å –∏–æ—Ç", "–∫–∞–±–µ–ª—å iot", "iot –∫–∞–±–µ–ª—å"}
        self._lock_keywords = {"–∑–∞–º–æ–∫", "–∑–∞–º–∫–∏", "–¥–≤–µ—Ä–Ω–æ–π –∑–∞–º–æ–∫", "–¥–≤–µ—Ä–Ω—ã–µ –∑–∞–º–∫–∏", "–∑–∞–º–∫–∏ iot", "–∑–∞–º–∫–∏ –∏–æ—Ç", "iot –∑–∞–º–æ–∫"}
        self._easycool_keywords = {
            "–∏–∑–∏–∫—É–ª", "easycool", "–∏–∑–∏ –∫—É–ª", "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∏–∑–∏–∫—É–ª", "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–∏–∫—É–ª",
            "–ø–∞—Å–ø–æ—Ä—Ç –Ω–∞ –∏–∑–∏–∫—É–ª", "–Ω—É–∂–Ω–∞ —Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∏–∑–∏–∫—É–ª", "–∏–∑–∏–∫—É–ª –±–∞—Å–ø—Ä–æ", "–∏–∑–∏–∫—É–ª knx", "–∏–∑–∏–∫—É–ª buspro"
        }
        self._curtain_general_keywords = {
            "–∫–∞—Ä–Ω–∏–∑", "–∫–∞—Ä–Ω–∏–∑—ã", "—Ä–∞–¥–∏—É—Å–Ω—ã–π –∫–∞—Ä–Ω–∏–∑", "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –∫–∞—Ä–Ω–∏–∑—ã",
            "–ø–∞—Å–ø–æ—Ä—Ç –∫–∞—Ä–Ω–∏–∑–æ–≤", "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∫–∞—Ä–Ω–∏–∑", "–∫–∞—Ä–Ω–∏–∑ –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª—É"
        }
        self._ac_general_keywords = {
            "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä", "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã", "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã –±–∞—Å–ø—Ä–æ", "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã —Å–æ–≤–º–µ—Å—Ç–∏–º—ã",
            "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã –º–æ–¥–µ–ª–∏", "—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–æ–≤", "–∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º",
            "—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–æ–≤", "–ø–∞—Å–ø–æ—Ä—Ç –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–∞", "—Ç–µ—Ö–Ω–∏—á–∫–∞ –Ω–∞ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä"
        }

    def load_index(self) -> List[Dict[str, Any]]:
        try:
            if os.path.exists(self.index_file):
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        return list(data.values())
                    return data
            else:
                logging.warning(f"Index file {self.index_file} not found")
                return []
        except Exception as e:
            logging.error(f"Error loading index: {e}")
            return []

    def normalize_text(self, text: str) -> str:
        if not text:
            return ""
        if text in self._normalize_cache:
            return self._normalize_cache[text]
        normalized = normalize_with_synonyms(text)
        self._normalize_cache[text] = normalized
        return normalized

    def expand_synonyms(self, query: str) -> List[str]:
        normalized_query = self.normalize_text(query)
        words = normalized_query.split()
        if not words:
            return [normalized_query]
        expanded_queries = {normalized_query}
        for i, word in enumerate(words):
            if word in self.synonyms:
                for synonym in self.synonyms[word]:
                    new_words = words.copy()
                    new_words[i] = synonym
                    expanded_queries.add(' '.join(new_words))
        return list(expanded_queries)

    def should_redirect_to_folder(self, query: str) -> Tuple[bool, str]:
        query_lower = query.lower().strip()
        logging.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è: '{query}' -> '{query_lower}'")

        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if query_lower in self.folder_links:
            logging.info(f"üéØ –¢–û–ß–ù–û–ï –°–û–í–ü–ê–î–ï–ù–ò–ï: '{query}' -> –ø–∞–ø–∫–∞")
            return True, self.folder_links[query_lower]

        # –ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã
        if any(kw in query_lower for kw in self._ac_general_keywords):
            logging.info(f"üéØ –û–ë–©–ò–ô –ó–ê–ü–†–û–° –ü–†–û –ö–û–ù–î–ò–¶–ò–û–ù–ï–†–´: '{query}' ‚Üí –æ–±–µ –ø–∞–ø–∫–∏")
            return True, "__AC_BOTH__"

        # –ö–∞—Ä–Ω–∏–∑—ã
        if any(kw in query_lower for kw in self._curtain_general_keywords):
            logging.info(f"üéØ –û–ë–©–ò–ô –ó–ê–ü–†–û–° –ü–†–û –ö–ê–†–ù–ò–ó–´: '{query}' ‚Üí –æ–±–µ –ø–∞–ø–∫–∏")
            return True, "__CURTAINS_BOTH__"

        # EasyCool
        easycool_patterns = ["–∏–∑–∏–∫—É–ª", "easycool", "–∏–∑–∏ –∫—É–ª"]
        if any(pattern in query_lower for pattern in easycool_patterns):
            logging.info(f"üéØ EASYCOOL –ó–ê–ü–†–û–°: '{query}' -> –ø–∞–ø–∫–∞ Easycool")
            return True, self.folder_links["–∏–∑–∏–∫—É–ª"]

        # –ò—Å–∫–ª—é—á–∞–µ–º KNX –∏–∑ –æ–±—â–∏—Ö –ø—Ä–∞–≤–∏–ª (–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ)
        if "knx" in query_lower:
            return False, ""

        # –ö–∞–±–µ–ª–∏ –∏ –∑–∞–º–∫–∏
        if any(kw in query_lower for kw in self._cable_keywords) and "knx" not in query_lower:
            return True, self.folder_links["–∫–∞–±–µ–ª—å"]
        if any(kw in query_lower for kw in self._lock_keywords):
            return True, self.folder_links["–∑–∞–º–∫–∏"]

        logging.info(f"‚ùå –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è: '{query}'")
        return False, ""

    def is_knx_cable_query(self, query: str) -> bool:
        query_lower = query.lower().strip()
        exact_knx_queries = {
            "–∫–∞–±–µ–ª—å knx", "knx –∫–∞–±–µ–ª—å", "cable knx", "knx cable",
            "knx –∫–∞–±–µ–ª", "ye00820", "j-y(st)y", "2x2x0,8"
        }
        if any(exact_query in query_lower for exact_query in exact_knx_queries):
            return True
        words = set(query_lower.split())
        has_knx = any("knx" in word for word in words)
        has_cable = any(word in {"–∫–∞–±–µ–ª—å", "cable", "–∫–∞–±–µ–ª"} for word in words)
        return has_knx and has_cable

    def is_alisa_integration_query(self, query: str) -> bool:
        query_lower = query.lower()
        has_alisa = any(keyword in query_lower for keyword in self._alisa_keywords)
        has_integration = any(keyword in query_lower for keyword in self._integration_keywords)
        return has_alisa and has_integration

    def get_alisa_integration_link(self) -> str:
        return self.folder_links["–∞–ª–∏—Å–∞"]

    def find_knx_cable_files(self) -> List[Dict[str, Any]]:
        knx_cable_keywords = [
            "ye00820", "j-y(st)y", "2x2x0,8", "knx –∫–∞–±–µ–ª—å", "–∫–∞–±–µ–ª—å knx", "–∫–∞–±–µ–ª—å j-y", "j-y st y"
        ]
        scored_files = []
        for file_data in self.file_index:
            file_name = file_data.get("name", "").lower()
            file_path = file_data.get("path", "").lower()
            search_text = f"{file_name} {file_path}"
            score = 0
            for i, keyword in enumerate(knx_cable_keywords):
                if keyword in search_text:
                    score += (len(knx_cable_keywords) - i) * 100
            if score > 0:
                scored_files.append((score, file_data))
        scored_files.sort(key=lambda x: x[0], reverse=True)
        return [file_data for score, file_data in scored_files]

    def filter_irrelevant_results(self, results: List[Dict], query: str) -> List[Dict]:
        if not results:
            return []
        query_lower = query.lower()
        filtered_results = []
        for result in results:
            name = result.get('name', '').lower()
            if any(w in query_lower for w in ['–∏–Ω—Ç–µ–≥—Ä–∞—Ü', '–ø—Ä–æ—Ç–æ–∫–æ–ª', 'api', '–Ω–∞—Å—Ç—Ä–æ–π–∫', '–∫–∞–∫']):
                if any(t in name for t in ['–ø–∞—Å–ø–æ—Ä—Ç', 'datasheet', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫', 'r5-', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π']):
                    continue
            if '–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä' in query_lower or 'controller' in query_lower:
                if any(irr in name for irr in ['–¥–∞—Ç—á–∏–∫', 'sensor', '—Ä–µ–ª–µ', 'relay', '–∫–∞–±–µ–ª—å', 'cable']):
                    continue
            filtered_results.append(result)
        return filtered_results

    def calculate_relevance(self, file_data: Dict[str, Any], query_variants: List[str]) -> float:
        max_score = 0
        file_name = file_data.get("name", "").lower()
        file_path = file_data.get("path", "").lower()
        norm_name = file_data.get("norm_name", "").lower()
        search_text = f"{file_name} {file_path} {norm_name}"
        for query in query_variants:
            score = 0
            query_words = set(query.split())
            if query in file_name:
                score += 10
            if query_words.issubset(set(file_name.split())):
                score += 8
            if query in norm_name:
                score += 7
            if query in file_path:
                score += 6
            name_similarity = SequenceMatcher(None, query, file_name).ratio()
            path_similarity = SequenceMatcher(None, query, file_path).ratio()
            score += max(name_similarity, path_similarity) * 5
            for word in query_words:
                if word in file_name:
                    score += 2
                if word in norm_name:
                    score += 3
                if word in file_path:
                    score += 1
            if "–∫–∞–±–µ–ª—å" in query and "knx" in query:
                knx_bonus = {
                    "ye00820": 100,
                    "j-y(st)y": 80,
                    "2x2x0,8": 60,
                    "knx –∫–∞–±–µ–ª—å": 40,
                    "–∫–∞–±–µ–ª—å knx": 40
                }
                for kw, bonus in knx_bonus.items():
                    if kw in search_text:
                        score += bonus
                if "–¥–∞—Ç—á–∏–∫" in search_text:
                    score -= 50
            max_score = max(max_score, score)
        return max_score

    def search(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        if not query or not self.file_index:
            return []
        query_variants = self.expand_synonyms(query)
        scored_results = []
        for file_data in self.file_index:
            relevance = self.calculate_relevance(file_data, query_variants)
            if relevance > 0:
                scored_results.append({**file_data, "relevance": relevance})
        scored_results.sort(key=lambda x: x["relevance"], reverse=True)
        return scored_results[:limit]

    def hybrid_search(self, query: str, limit: int = 3) -> List[Dict[str, Any]]:
        # –ê–ª–∏—Å–∞
        if self.is_alisa_integration_query(query):
            return [{
                "name": "üìÅ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –Ø–Ω–¥–µ–∫—Å –ê–ª–∏—Å–æ–π",
                "path": self.get_alisa_integration_link(),
                "is_folder_link": True,
                "folder_link": self.get_alisa_integration_link()
            }]

        # KNX –∫–∞–±–µ–ª—å
        if self.is_knx_cable_query(query):
            knx_results = self.find_knx_cable_files()
            if knx_results:
                return knx_results[:limit]

        # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        should_redirect, folder_link = self.should_redirect_to_folder(query)
        if should_redirect:
            if folder_link == "__CURTAINS_BOTH__":
                return [
                    {"name": "Buspro", "path": "https://disk.360.yandex.ru/d/20Q51Ey5rDMXqA", "is_folder_link": True, "folder_link": "https://disk.360.yandex.ru/d/20Q51Ey5rDMXqA"},
                    {"name": "KNX", "path": "https://disk.360.yandex.ru/d/x1w6XEUthCgTVg", "is_folder_link": True, "folder_link": "https://disk.360.yandex.ru/d/x1w6XEUthCgTVg"}
                ]
            elif folder_link == "__AC_BOTH__":
                return [
                    {"name": "–î–ª—è EasyCool", "path": "https://disk.360.yandex.ru/d/EuWsEkI__LPmIQ", "is_folder_link": True, "folder_link": "https://disk.360.yandex.ru/d/EuWsEkI__LPmIQ"},
                    {"name": "–î–ª—è CoolAutomation", "path": "https://disk.360.yandex.ru/d/UVzihaR7eRIRmw", "is_folder_link": True, "folder_link": "https://disk.360.yandex.ru/d/UVzihaR7eRIRmw"}
                ]
            else:
                return [{
                    "name": f"üìÅ –ü–∞–ø–∫–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π: {query}",
                    "path": folder_link,
                    "is_folder_link": True,
                    "folder_link": folder_link
                }]

        # –û–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
        improved_results = self.search(query, limit * 2)
        improved_results = self.filter_irrelevant_results(improved_results, query)
        if improved_results:
            return improved_results[:limit]

        # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π –ø–æ–∏—Å–∫
        try:
            old_results = self.old_smart_search(query)
            return old_results[:limit]
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç–∞—Ä–æ–º –ø–æ–∏—Å–∫–µ: {e}")
            return []

    def old_smart_search(self, query: str, limit: int = 3) -> List[Dict]:
        if not self.file_index:
            return []
        query_norm = self.normalize_text(query)
        if not query_norm:
            return []
        exact_results = self._old_search_exact_match(query_norm)
        if exact_results:
            return exact_results[:limit]
        combo_results = self._old_search_keyword_combinations(query_norm)
        if combo_results:
            return combo_results[:limit]
        important_results = self._old_search_important_keywords(query_norm)
        if important_results:
            return important_results[:limit]
        return []

    def _old_search_exact_match(self, query_norm: str) -> List[Dict]:
        keywords = [word for word in query_norm.split() if len(word) >= 2]
        if not keywords:
            return []
        results = []
        for file_data in self.file_index:
            norm_name = file_data.get("norm_name", "")
            if all(kw in norm_name for kw in keywords):
                results.append(file_data)
        return results

    def _old_search_keyword_combinations(self, query_norm: str) -> List[Dict]:
        keywords = [word for word in query_norm.split() if len(word) >= 2]
        if len(keywords) < 2:
            return []
        scored_files = []
        for file_data in self.file_index:
            norm_name = file_data.get("norm_name", "")
            file_name = file_data.get("name", "").lower()
            score = sum(20 for kw in keywords if kw in norm_name)
            score += sum(10 for kw in keywords if kw in file_name)
            if score > 0:
                scored_files.append((score, file_data))
        scored_files.sort(key=lambda x: x[0], reverse=True)
        return [fd for _, fd in scored_files]

    def _old_search_important_keywords(self, query_norm: str) -> List[Dict]:
        important_keywords = {"alisa", "knx", "integration", "connect", "gateway", "voice"}
        found = [kw for kw in important_keywords if kw in query_norm]
        if not found:
            return []
        scored = []
        for file_data in self.file_index:
            norm_name = file_data.get("norm_name", "")
            score = sum(30 for kw in found if kw in norm_name)
            if score > 0:
                scored.append((score, file_data))
        scored.sort(key=lambda x: x[0], reverse=True)
        return [fd for _, fd in scored]


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async def smart_document_search(query: str, limit: int = 3) -> List[Dict[str, Any]]:
    try:
        search_engine = SearchEngine()
        return search_engine.hybrid_search(query, limit)
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ smart_document_search: {e}")
        return []


def search_in_file_index(query: str, index_path: str = "data/cache/file_index.json") -> List[Dict]:
    search_engine = SearchEngine(index_path)
    return search_engine.search(query)


def has_only_technical_files(results: List[Dict[str, Any]]) -> bool:
    if results and results[0].get("is_folder_link"):
        return False
    technical_patterns = ["r5-", "–¥–∞—Ç—á–∏–∫", "sensor", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫", "–ø–∞—Å–ø–æ—Ä—Ç", "technical"]
    for file_data in results:
        name = file_data.get("name", "").lower()
        if not any(p in name for p in technical_patterns):
            return False
    return True


def should_use_ai_directly(query: str) -> bool:
    query_lower = query.lower()
    alisa_keywords = {
        "–∞–ª–∏—Å", "—è–Ω–¥–µ–∫—Å –∞–ª–∏—Å", "yandex alice", "alisa", "mgwip",
        "–≥–æ–ª–æ—Å–æ–≤", "–≥–æ–ª–æ—Å–æ–≤–æ–π", "–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", "—à–ª—é–∑", "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏"
    }
    if any(kw in query_lower for kw in alisa_keywords):
        return False
    complex_question_words = {
        "–ø–æ—á–µ–º—É", "–∫–∞–∫–æ–π –ª—É—á—à–µ", "—á—Ç–æ –≤—ã–±—Ä–∞—Ç—å", "—Å—Ä–∞–≤–Ω–∏", "–æ—Ç–ª–∏—á–∏—è",
        "–ø—Ä–æ–±–ª–µ–º–∞", "–æ—à–∏–±–∫–∞", "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "–Ω–µ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è", "—Å–ª–æ–º–∞–ª"
    }
    is_complex = any(w in query_lower for w in complex_question_words)
    if is_complex and not any(kw in query_lower for kw in alisa_keywords):
        return True
    return False